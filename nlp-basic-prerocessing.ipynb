{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-27T08:28:07.406519Z","iopub.execute_input":"2024-08-27T08:28:07.407326Z","iopub.status.idle":"2024-08-27T08:28:07.880460Z","shell.execute_reply.started":"2024-08-27T08:28:07.407274Z","shell.execute_reply":"2024-08-27T08:28:07.879311Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")\ndf.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:28:32.174086Z","iopub.execute_input":"2024-08-27T08:28:32.174575Z","iopub.status.idle":"2024-08-27T08:28:32.952333Z","shell.execute_reply.started":"2024-08-27T08:28:32.174520Z","shell.execute_reply":"2024-08-27T08:28:32.951016Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df[\"review\"]=df[\"review\"].str.lower()\ndf.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:28:56.642195Z","iopub.execute_input":"2024-08-27T08:28:56.642712Z","iopub.status.idle":"2024-08-27T08:28:56.870816Z","shell.execute_reply.started":"2024-08-27T08:28:56.642643Z","shell.execute_reply":"2024-08-27T08:28:56.869524Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  one of the other reviewers has mentioned that ...  positive\n1  a wonderful little production. <br /><br />the...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>one of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# remove html tags","metadata":{}},{"cell_type":"code","source":"import re\n\ndef removeTags(text):\n    data = re.compile('<.*?>')\n    return re.sub(data,\"\",text)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:32:22.869650Z","iopub.execute_input":"2024-08-27T08:32:22.870123Z","iopub.status.idle":"2024-08-27T08:32:22.876580Z","shell.execute_reply.started":"2024-08-27T08:32:22.870079Z","shell.execute_reply":"2024-08-27T08:32:22.875174Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df[\"review\"]=df[\"review\"].apply(removeTags)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:32:34.973808Z","iopub.execute_input":"2024-08-27T08:32:34.974235Z","iopub.status.idle":"2024-08-27T08:32:35.310995Z","shell.execute_reply.started":"2024-08-27T08:32:34.974193Z","shell.execute_reply":"2024-08-27T08:32:35.309909Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# remove urls\n","metadata":{}},{"cell_type":"code","source":"def removeUrls(text):\n    data = re.compile(r'https?://\\S+|www\\.\\S+') \n    return re.sub(data,\"\",text)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:37:47.085881Z","iopub.execute_input":"2024-08-27T08:37:47.086315Z","iopub.status.idle":"2024-08-27T08:37:47.091966Z","shell.execute_reply.started":"2024-08-27T08:37:47.086273Z","shell.execute_reply":"2024-08-27T08:37:47.090744Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"removeUrls(\"hellow join us at www.gogle.com\")","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:37:48.524597Z","iopub.execute_input":"2024-08-27T08:37:48.525080Z","iopub.status.idle":"2024-08-27T08:37:48.533021Z","shell.execute_reply.started":"2024-08-27T08:37:48.525034Z","shell.execute_reply":"2024-08-27T08:37:48.531627Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"'hellow join us at '"},"metadata":{}}]},{"cell_type":"markdown","source":"# Removing Punctuation","metadata":{}},{"cell_type":"code","source":"import string\nexclude = string.punctuation\nexclude","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:38:28.151980Z","iopub.execute_input":"2024-08-27T08:38:28.152463Z","iopub.status.idle":"2024-08-27T08:38:28.160387Z","shell.execute_reply.started":"2024-08-27T08:38:28.152403Z","shell.execute_reply":"2024-08-27T08:38:28.159110Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"},"metadata":{}}]},{"cell_type":"code","source":"def removepunc(text):\n    return text.translate(str.maketrans('','',exclude))","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:39:07.193876Z","iopub.execute_input":"2024-08-27T08:39:07.194260Z","iopub.status.idle":"2024-08-27T08:39:07.200283Z","shell.execute_reply.started":"2024-08-27T08:39:07.194223Z","shell.execute_reply":"2024-08-27T08:39:07.199039Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df[\"review\"]=df[\"review\"].apply(removepunc)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:39:32.391019Z","iopub.execute_input":"2024-08-27T08:39:32.391446Z","iopub.status.idle":"2024-08-27T08:39:33.863762Z","shell.execute_reply.started":"2024-08-27T08:39:32.391401Z","shell.execute_reply":"2024-08-27T08:39:33.862607Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# Chatword treatment","metadata":{}},{"cell_type":"code","source":"chat_words_dict = {\n    \"hello\": \"A greeting or expression of goodwill\",\n    \"brb\": \"Be right back\",\n    \"lol\": \"Laugh out loud\",\n    \"omg\": \"Oh my God\",\n    \"idk\": \"I don't know\",\n    \"btw\": \"By the way\",\n    \"gtg\": \"Got to go\",\n    \"ttyl\": \"Talk to you later\",\n    \"np\": \"No problem\",\n    \"thx\": \"Thanks\",\n    \"yw\": \"You're welcome\",\n    \"imo\": \"In my opinion\",\n    \"fyi\": \"For your information\",\n    \"asap\": \"As soon as possible\",\n    \"bff\": \"Best friends forever\",\n    \"tbh\": \"To be honest\",\n    \"smh\": \"Shaking my head\",\n    \"afaik\": \"As far as I know\",\n    \"irl\": \"In real life\",\n    \"dm\": \"Direct message\",\n    \"rofl\": \"Rolling on the floor laughing\",\n    \"lmao\": \"Laughing my ass off\",\n    \"bbl\": \"Be back later\",\n    \"gr8\": \"Great\",\n    \"jk\": \"Just kidding\",\n    \"nvm\": \"Never mind\",\n    \"omw\": \"On my way\",\n    \"ppl\": \"People\",\n    \"pls\": \"Please\",\n    \"thx\": \"Thanks\",\n    \"u\": \"You\",\n    \"ur\": \"Your\",\n    \"w/e\": \"Whatever\",\n    \"w/o\": \"Without\",\n    \"w8\": \"Wait\",\n    \"xoxo\": \"Hugs and kisses\",\n    \"yolo\": \"You only live once\",\n    \"b4\": \"Before\",\n    \"cya\": \"See you\",\n    \"ez\": \"Easy\",\n    \"faq\": \"Frequently asked questions\",\n    \"ftw\": \"For the win\",\n    \"gg\": \"Good game\",\n    \"gl\": \"Good luck\",\n    \"hf\": \"Have fun\",\n    \"hmu\": \"Hit me up\",\n    \"ic\": \"I see\",\n    \"imo\": \"In my opinion\",\n    \"irl\": \"In real life\",\n    \"jk\": \"Just kidding\",\n    \"k\": \"Okay\",\n    \"lmk\": \"Let me know\",\n    \"msg\": \"Message\",\n    \"n/a\": \"Not applicable\",\n    \"np\": \"No problem\",\n    \"omg\": \"Oh my God\",\n    \"plz\": \"Please\",\n    \"q\": \"Question\",\n    \"r\": \"Are\",\n    \"rn\": \"Right now\",\n    \"sry\": \"Sorry\",\n    \"tba\": \"To be announced\",\n    \"tbd\": \"To be decided\",\n    \"tgif\": \"Thank God it's Friday\",\n    \"thx\": \"Thanks\",\n    \"ttyl\": \"Talk to you later\",\n    \"u\": \"You\",\n    \"ur\": \"Your\",\n    \"w/\": \"With\",\n    \"w/o\": \"Without\",\n    \"w8\": \"Wait\",\n    \"xoxo\": \"Hugs and kisses\",\n    \"yolo\": \"You only live once\",\n    \"b4\": \"Before\",\n    \"cya\": \"See you\",\n    \"ez\": \"Easy\",\n    \"faq\": \"Frequently asked questions\",\n    \"ftw\": \"For the win\",\n    \"gg\": \"Good game\",\n    \"gl\": \"Good luck\",\n    \"hf\": \"Have fun\",\n    \"hmu\": \"Hit me up\",\n    \"ic\": \"I see\",\n    \"imo\": \"In my opinion\",\n    \"irl\": \"In real life\",\n    \"jk\": \"Just kidding\",\n    \"k\": \"Okay\",\n    \"lmk\": \"Let me know\",\n    \"msg\": \"Message\",\n    \"n/a\": \"Not applicable\",\n    \"np\": \"No problem\",\n    \"omg\": \"Oh my God\",\n    \"plz\": \"Please\",\n    \"q\": \"Question\",\n    \"r\": \"Are\",\n    \"rn\": \"Right now\",\n    \"sry\": \"Sorry\",\n    \"tba\": \"To be announced\",\n    \"tbd\": \"To be decided\",\n    \"tgif\": \"Thank God it's Friday\",\n    \"thx\": \"Thanks\",\n    \"ttyl\": \"Talk to you later\",\n    \"u\": \"You\",\n    \"ur\": \"Your\",\n    \"w/\": \"With\",\n    \"w/o\": \"Without\",\n    \"w8\": \"Wait\",\n    \"xoxo\": \"Hugs and kisses\",\n    \"yolo\": \"You only live once\"\n}\nchat_words_dict","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:45:46.702406Z","iopub.execute_input":"2024-08-27T08:45:46.702901Z","iopub.status.idle":"2024-08-27T08:45:46.774102Z","shell.execute_reply.started":"2024-08-27T08:45:46.702853Z","shell.execute_reply":"2024-08-27T08:45:46.772037Z"},"trusted":true},"execution_count":35,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[35], line 112\u001b[0m\n\u001b[1;32m      1\u001b[0m chat_words_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA greeting or expression of goodwill\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrb\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBe right back\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou only live once\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m }\n\u001b[0;32m--> 112\u001b[0m \u001b[43mchat_words_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m()\u001b[38;5;241m.\u001b[39mshape\n","\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'toarray'"],"ename":"AttributeError","evalue":"'dict' object has no attribute 'toarray'","output_type":"error"}]},{"cell_type":"code","source":"def ChatWwordsTreatment(text):\n    new_text=[]\n    for w in text.split():\n        if w in chat_words_dict:\n            new_text.append(chat_words_dict[w])\n        else:\n            new_text.append(w)\n    return \" \".join(new_text)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:49:38.921441Z","iopub.execute_input":"2024-08-27T08:49:38.922311Z","iopub.status.idle":"2024-08-27T08:49:38.930144Z","shell.execute_reply.started":"2024-08-27T08:49:38.922259Z","shell.execute_reply":"2024-08-27T08:49:38.928327Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"ChatWwordsTreatment(\"tbd i am going to gemrany\")","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:49:41.151856Z","iopub.execute_input":"2024-08-27T08:49:41.153106Z","iopub.status.idle":"2024-08-27T08:49:41.161541Z","shell.execute_reply.started":"2024-08-27T08:49:41.153050Z","shell.execute_reply":"2024-08-27T08:49:41.160031Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"'To be decided i am going to gemrany'"},"metadata":{}}]},{"cell_type":"code","source":"ChatWwordsTreatment(\"nvm i am going to gemrany\")","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:50:11.918407Z","iopub.execute_input":"2024-08-27T08:50:11.919252Z","iopub.status.idle":"2024-08-27T08:50:11.927244Z","shell.execute_reply.started":"2024-08-27T08:50:11.919193Z","shell.execute_reply":"2024-08-27T08:50:11.925759Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"'Never mind i am going to gemrany'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Spelling Correction","metadata":{}},{"cell_type":"code","source":"from textblob import TextBlob\n\nincorrect_sentence=\"certain candetion are vory bade\"\n\ncorrectcion = TextBlob(incorrect_sentence)\n\ncorrection.correct().string","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:58:51.158271Z","iopub.execute_input":"2024-08-27T08:58:51.158779Z","iopub.status.idle":"2024-08-27T08:58:51.654147Z","shell.execute_reply.started":"2024-08-27T08:58:51.158732Z","shell.execute_reply":"2024-08-27T08:58:51.652791Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"'certain condition are very bade'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Stop_Words_Removing","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\nprint(stopwords.words(\"english\"))","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:14:01.394109Z","iopub.execute_input":"2024-08-27T09:14:01.394597Z","iopub.status.idle":"2024-08-27T09:14:01.401563Z","shell.execute_reply.started":"2024-08-27T09:14:01.394555Z","shell.execute_reply":"2024-08-27T09:14:01.400393Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n","output_type":"stream"}]},{"cell_type":"code","source":"def removeStopwords(text):\n    new_text=[]\n    for w in text.split():\n        if w in stopwords.words(\"english\"):\n            new_text.append(\"\")\n        else:\n            new_text.append(w)\n    return \" \".join(new_text)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:19:15.999970Z","iopub.execute_input":"2024-08-27T09:19:16.000438Z","iopub.status.idle":"2024-08-27T09:19:16.007158Z","shell.execute_reply.started":"2024-08-27T09:19:16.000393Z","shell.execute_reply":"2024-08-27T09:19:16.005787Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"df[\"review\"]=df[\"review\"].apply(removeStopwords)\ndf[\"review\"].head(20)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:23:16.139780Z","iopub.execute_input":"2024-08-27T09:23:16.140229Z","iopub.status.idle":"2024-08-27T09:27:24.496971Z","shell.execute_reply.started":"2024-08-27T09:23:16.140176Z","shell.execute_reply":"2024-08-27T09:27:24.494655Z"},"trusted":true},"execution_count":86,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[86], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreview\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremoveStopwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m20\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n","File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","Cell \u001b[0;32mIn[83], line 4\u001b[0m, in \u001b[0;36mremoveStopwords\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m new_text\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m text\u001b[38;5;241m.\u001b[39msplit():\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstopwords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menglish\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      5\u001b[0m         new_text\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/reader/wordlist.py:22\u001b[0m, in \u001b[0;36mWordListCorpusReader.words\u001b[0;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwords\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ignore_lines_startswith\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [line \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[43mline_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstartswith(ignore_lines_startswith)]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/tokenize/simple.py:133\u001b[0m, in \u001b[0;36mline_tokenize\u001b[0;34m(text, blanklines)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mline_tokenize\u001b[39m(text, blanklines\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscard\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLineTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblanklines\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/tokenize/simple.py:112\u001b[0m, in \u001b[0;36mLineTokenizer.tokenize\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# If requested, strip off blank lines.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blanklines \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscard\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 112\u001b[0m     lines \u001b[38;5;241m=\u001b[39m [l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lines \u001b[38;5;28;01mif\u001b[39;00m l\u001b[38;5;241m.\u001b[39mrstrip()]\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blanklines \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscard-eof\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lines \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lines[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip():\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/tokenize/simple.py:112\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# If requested, strip off blank lines.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blanklines \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscard\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 112\u001b[0m     lines \u001b[38;5;241m=\u001b[39m [l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lines \u001b[38;5;28;01mif\u001b[39;00m l\u001b[38;5;241m.\u001b[39mrstrip()]\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blanklines \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscard-eof\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lines \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lines[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip():\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"# Handling_Emjoies","metadata":{}},{"cell_type":"code","source":"import re\n\ndef remove_emojies(text):\n    emojies_pattren = re.compile(\"[\"\n        \"\\U0001F600-\\U0001F64F\"  # emoticons\n        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n        \"\\U00002702-\\U000027B0\"  # Dingbats\n        \"\\U000024C2-\\U0001F251\" \n        \"]+\", flags=re.UNICODE\n                                )\n    text = re.sub(emojies_pattren,\"\",text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:27:32.614857Z","iopub.execute_input":"2024-08-27T09:27:32.615290Z","iopub.status.idle":"2024-08-27T09:27:32.622348Z","shell.execute_reply.started":"2024-08-27T09:27:32.615248Z","shell.execute_reply":"2024-08-27T09:27:32.620775Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"remove_emojies(\"Hello ðŸ˜Š! How are you doing today? ðŸš€\")","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:28:10.078466Z","iopub.execute_input":"2024-08-27T09:28:10.078914Z","iopub.status.idle":"2024-08-27T09:28:10.092069Z","shell.execute_reply.started":"2024-08-27T09:28:10.078874Z","shell.execute_reply":"2024-08-27T09:28:10.090884Z"},"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"'Hello ! How are you doing today? '"},"metadata":{}}]},{"cell_type":"code","source":"import emoji\nprint(emoji.demojize(\"Hello ðŸ˜Š! How are you doing today? ðŸš€\"))","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:30:24.746860Z","iopub.execute_input":"2024-08-27T09:30:24.747313Z","iopub.status.idle":"2024-08-27T09:30:24.822655Z","shell.execute_reply.started":"2024-08-27T09:30:24.747267Z","shell.execute_reply":"2024-08-27T09:30:24.821513Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"Hello :smiling_face_with_smiling_eyes:! How are you doing today? :rocket:\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Tokenization \n# 1: Word Token\n# 2: Sentence Token","metadata":{}},{"cell_type":"code","source":"sentnce = \"i am going to islamabd\"\nsentnce.split()","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:38:23.313981Z","iopub.execute_input":"2024-08-27T09:38:23.314424Z","iopub.status.idle":"2024-08-27T09:38:23.322531Z","shell.execute_reply.started":"2024-08-27T09:38:23.314379Z","shell.execute_reply":"2024-08-27T09:38:23.321354Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"['i', 'am', 'going', 'to', 'islamabd']"},"metadata":{}}]},{"cell_type":"code","source":"sentnce = \"i am going to islamabd.my friend is moving to lahore\"\nsentnce.split(\".\")","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:40:30.866573Z","iopub.execute_input":"2024-08-27T09:40:30.867747Z","iopub.status.idle":"2024-08-27T09:40:30.880518Z","shell.execute_reply.started":"2024-08-27T09:40:30.867696Z","shell.execute_reply":"2024-08-27T09:40:30.879255Z"},"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"['i am going to islamabd', 'my friend is moving to lahore']"},"metadata":{}}]},{"cell_type":"code","source":"#Nltk\n\nfrom nltk.tokenize import word_tokenize,sent_tokenize\nsent = \"i have ph.D  in A.i\"\nword_tokenize(sent)\n\n#Spacy is also a best option for tokenization\n\nimport spacy\nnlp = spacy.load(\"en_core_web_sm\")\n\nsent2 = \"mail us at warishayat69@gmail.com\"\n\ndoc1 = nlp(sent2)\n\nfor token in doc1:\n    print(token)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:52:43.408729Z","iopub.execute_input":"2024-08-27T09:52:43.409323Z","iopub.status.idle":"2024-08-27T09:52:44.874499Z","shell.execute_reply.started":"2024-08-27T09:52:43.409253Z","shell.execute_reply":"2024-08-27T09:52:44.873074Z"},"trusted":true},"execution_count":113,"outputs":[{"name":"stdout","text":"mail\nus\nat\nwarishayat69@gmail.com\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Lemmatizer/Stemming","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.stem import WordNetLemmatizer\nlemitizer = WordNetLemmatizer()\nsentence = \"we as running and eating at the same time. we had habit of stemming after playing long hour sin the son\"\npunctuation = \".?!,:;\"\nsent_word = nltk.word_tokenize(sentence)\nfor word in sent_word:\n    if word in punctuation:\n        sent_word.remove(word)\n        \nprint(\"{0:20}{0:20}\".format(\"word\",\"Lemma\"))\nfor word in sent_word:\n    print(\"{0:20}{0:20}\".format(word,lemitizer.lemmatize(word,pos=\"v\")))","metadata":{"execution":{"iopub.status.busy":"2024-08-27T10:18:52.940850Z","iopub.execute_input":"2024-08-27T10:18:52.941283Z","iopub.status.idle":"2024-08-27T10:18:53.121302Z","shell.execute_reply.started":"2024-08-27T10:18:52.941235Z","shell.execute_reply":"2024-08-27T10:18:53.119117Z"},"trusted":true},"execution_count":125,"outputs":[{"name":"stdout","text":"word                word                \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:80\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzip_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m e\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/data.py:653\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    652\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (sep, msg, sep)\n\u001b[0;32m--> 653\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'corpora/wordnet.zip/wordnet/.zip/' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[125], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0:20}\u001b[39;00m\u001b[38;5;132;01m{0:20}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLemma\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sent_word:\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0:20}\u001b[39;00m\u001b[38;5;132;01m{0:20}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(word,\u001b[43mlemitizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/stem/wordnet.py:40\u001b[0m, in \u001b[0;36mWordNetLemmatizer.lemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize\u001b[39m(\u001b[38;5;28mself\u001b[39m, word, pos\u001b[38;5;241m=\u001b[39mNOUN):\n\u001b[0;32m---> 40\u001b[0m     lemmas \u001b[38;5;241m=\u001b[39m \u001b[43mwordnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_morphy\u001b[49m(word, pos)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(lemmas, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m lemmas \u001b[38;5;28;01melse\u001b[39;00m word\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:116\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m: root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir, zip_name))\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:78\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m: root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir, zip_name))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/data.py:653\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    651\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    652\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (sep, msg, sep)\n\u001b[0;32m--> 653\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'corpora/wordnet' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************"],"ename":"LookupError","evalue":"\n**********************************************************************\n  Resource 'corpora/wordnet' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}