# MachineLearning-DataScience100-Days
#100 days with Machine-Learning/Data-Science
<br>
Day1:
<br>
Today i read and practise all about csv files like how to import csv,and their functions like skiprows,indexcols,usecol, colums,na_pamater,convertor etc.
<br>
Day2:
<br>
Today i read and practise all about json and Sql files like how to import JSON,and How to work with Sql.
<br>
Day3:
<br>
Today i read and practise all about how to understand the data.
<br>
Day4:
<br>
Today i read about univariate Data Analysis and solve some practise level question.
<br>
Day5:
<br>
Today i read about bivariate Data Analysis and Multivariate Data analysis and solve some practise level datset.
<br>
Day6:
<br>
Today i read about Data_Profiling how to analyse the data in the form of html etc.
<br>
Day7:
<br>
Today i read about standard Scalar from Feature_Engineering.
<br>
Day8:
<br>
Today i read about normalization from Feature_Engineering.
<br>
Day9:
<br>
Today i read about Ordinanl Encoding from Feature_Engineering.
<br>
Day11:
<br>
Today i read about the ColumTransformer which is quite easy to do similar task that we do with labelencoder and ordinanl Encoder.
<br>
Day12:
<br>
Today i read about the sklearn pipelines and practise titanic datset.
<br>
Day13:
<br>
Today i read about the sklearn function transformer and practise titanic datset.
<br>
Day14:
<br>
Today i read about the sklearn power transformer.
<br>
Day15:
<br>
Today i make a project using all existing concept.
<br>
Day16:
<br>
Today i cover the mix data like how to handle mix data.
<br>
Day17:
<br>
Today i cover the how to handles date and time in the data.
<br>
Day18:
<br>
Today i cover the CCA -->Case complete analysis or removinf or droping the values.
<br>
Day19:
<br>
Today i cover the handling missing values or univariate handle mising values.
<br>
Day20:
<br>
Today i cover the handling missing categorical values.
<br>
Day21:
<br>
Today i cover the handling missing values with tecnique Fill with Random and Missing Indicator.
<br>
Day22:
<br>
Today i cover the Knn imputer and practise side by side comparision with simpleimputer,Knn imputer,missingindicator,random etc.
<br>
Day23:
<br>
Today i understand the concept of Multivariate Missing Imputer Concept.
<br>
Day24:
<br>
Today i wrote about the outlier at this day i take the concept of handling outlier with z score that mean data is normally distributed then we remove the outliers with tecniique  zcsore
<br>
like if i talk about the formoula that is: z_score=x-mean/std or 3+x(standard_diviation) for positive side and 3-x(standard_diviation) then we read the conceptt of capping and trrimming the data.
<br>
Day25:
<br>
Today i read about the another tecnique of handling outlier is IQR we do solve some question the formoula that we used in the IQR method is<br>
Q1-1.5*iqr and Q3+1.5*iqr .where IQR is the diffence between the value of 75% and 25%. and q1 is 25% of the total value where the q3 is the 75% of <br>
pf the total value.
<br>
Day25:
<br>
Today i read about the percentile tcehnique by using that how we can detact and remove outliers.
<br>
Day26:
<br>
Today i read about the feature contsruction like how to construct new columns from existing data and i learn how to do feature split..
<br>
Day27:
<br>
Today i read about the curse of dimensionality where the dimensionality mean feature and feature mean columns that if we have feature more then algoritham that can make the <br>
algoritham capacity decrease or it is not benifical for the algorithan  and it would increase the sparsity of the columns becuase of that the data point separate/fare from the mean<br>
in Curse of dimensionality use both for FEATURE SELECTION and FEATURE EXTRACTION.
<br>
For next one week i will be never upload/task because first i solve the task then i upload to the github but my exam is ongoing because of that i am not avialabale <br>
But i will maintain my strea with github by updating thge readme..
<br>
<br>
<br>
<br>
leave for exam
<br>
leave for exam
<br>
leave for exam
<br>
leave for exam
<br>
leave for exam
<br>
leave for exam
<br>
leave for exam
<br>
leave for exam
<br>
leave for exam
<br>
<br>
<br>
<br>
<br>
