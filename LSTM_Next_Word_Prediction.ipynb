{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "c62RIJ4XZu3z"
      },
      "outputs": [],
      "source": [
        "faqs = \"\"\" About the program\n",
        "What is the course fee for  Data Science Mentorship Program (DSMP 2.0)\n",
        "The total course fee for the DSMP course is Rs 10,600. This includes the fee for both DSMP 1.0 and DSMP 2.0\n",
        "What is the total duration of the course?\n",
        "The total duration of the course is about 6-8 months.\n",
        "Are Deep Learning and NLP a part of the DSMP 2.0  course?\n",
        "No, NLP and Deep Learning both are not a part of this program’s curriculum.\n",
        "What if I miss a live session? Will I get a recording of the session?\n",
        "Yes, all our sessions are recorded, so even if you miss a session you can login into our portal and watch the recording as per your convenience.\n",
        "Where can I find the class schedule?\n",
        "You will find the class schedule in your course dashboard once you enroll for the course.\n",
        "What is the time duration of all the live sessions?\n",
        "Roughly, all the sessions last 2 hours.\n",
        "What is the language spoken by the instructor during the sessions?\n",
        "Hinglish.\n",
        "How will I be informed about the upcoming class?\n",
        "You will get mail from our side before every session once you enroll in the course.\n",
        "Can I do this course if I am from a non-tech background?\n",
        "Yes, absolutely. However, you’ll need to be consistent.\n",
        "I am late, can I join the program in the middle?\n",
        "Absolutely, you can join the program any time.\n",
        "If I join/pay in the middle, will I be able to see all the past lectures?\n",
        "Yes, once you’re enrolled in the course, you will be able to see all the past content in your dashboard.\n",
        "Where do I have to submit the task?\n",
        "You don’t have to submit the task. We will provide you with the solutions, you have to self evaluate the task yourself.\n",
        "Will we do case studies in the program?\n",
        "Yes, there are 5 end to end case studies and multiple smaller projects.\n",
        "Do we offer any student discounts or promo codes?\n",
        "We do offer discounts on our courses a few times a year, and we announce them through our social media channels.\n",
        "On how many devices can I watch the videos simultaneously?\n",
        "You can watch the videos on one device at a time.\n",
        "Do you provide notes for the lectures?\n",
        "We do not provide notes for our lectures. We encourage students to make their own notes as it aids in study retention.\n",
        "What is the difference between being a paid member on your YouTube channel and your website?\n",
        "While the content on our YouTube channel and website is similar, enrolling through our website offers additional benefits such as doubt clearance support and access to an exclusive community of learners on Discord and more.\n",
        "Do I get access to your YouTube channel as a paid member after enrolling through your website?\n",
        "No, the YouTube channel membership is separate from what we offer on our website.\n",
        "Is there any upcoming batch for the Data Science Mentorship Program?\n",
        "Currently, we do not have any plans to launch a new batch for DSMP. However, all previous lectures are available as recordings, allowing you to learn at your own pace.\n",
        "Do you provide doubt clearance for the projects uploaded on CampusX YouTube channel?\n",
        "We do not provide doubt clearance for any of our videos or projects uploaded on YouTube. However, you can ask your doubts in our Discord channel or in the comments section.\n",
        "Payment/Registration related questions\n",
        "Where do we have to make our payments? Your YouTube channel or website?\n",
        "You have to make all your monthly payments on our website. Here is the link for our website - https://learnwith.campusx.in/\n",
        "What if I don’t like the course after making the payment? What is the refund policy?\n",
        "You get a 7 days refund period from the day you have made the payment. To apply for refund, send us an email at support@campusx.in\n",
        "I am living outside India and I am not able to make the payment on the website. What should I do?\n",
        "You can contact us by sending a mail at support@campusx.in\n",
        "I am from Pakistan and I am unable to make the payment?\n",
        "We currently do not have the option to accept payment from Pakistan directly. If you’d still like to enroll for the course, you may ask a friend or family member living outside Pakistan to make the fee payment on your behalf. If you’d like to proceed with manual enrollment, please contact us at support@campusx.in, and we’ll provide you with further instructions.\n",
        "Do you accept PayPal as a payment method?\n",
        "Yes, we do. Please contact us at support@campusx.in for more details on using PayPal for payment.\n",
        "I cannot pay the DSMP 2.0 fee as a one-time payment, is there any way to make a payment in installments?\n",
        "At the moment, we do not have a monthly payment plan for the DSMP 2.0 course. However, if you have financial constraints, you can enroll in DSMP 1.0 by paying 799/- a month. Once you complete the course, you may apply for a discount coupon from the website.\n",
        "Post registration queries\n",
        "Till when can I view the paid videos on the website?\n",
        "You can watch the videos till your subscription is valid, that is 3 years from the date of purchase for DSMP 2.0\n",
        "Why is lifetime validity not provided?\n",
        "Because of the low course fee.\n",
        "Do you assist with personal projects?\n",
        "We do not provide support for personal projects due to time constraints and current commitments.\n",
        "Where can I reach out in case of a doubt after the session?\n",
        "You will have to fill a google form provided in your dashboard and our team will contact you for a 1 on 1 doubt clearing session.\n",
        "If I join the program late, can I still ask past week doubts?\n",
        "Yes, just select “past week's doubt” in the doubt clearance google form.\n",
        "What is the validity of Doubt Support?\n",
        "You will get doubt support for 1 year from the data of registration.\n",
        "Certificate and Placement Assistance related queries\n",
        "What is the criteria to get the certificate?\n",
        "There are 2 criterias:\n",
        "You have to pay the entire fee of Rs 10,600\n",
        "You have to attempt all the course assessments.\n",
        "I have read that Job Preparation is a part of this program. What comes under Job Preparation?\n",
        "This is to clarify that Job Preparation does not mean Placement guarantee. We don't guarantee our learners any jobs or for that matter even interview calls. If you are planning to join this course just for placements, we’re afraid that this course might not be the best for you.\n",
        "Here is what comes under Job Preparation\n",
        "Portfolio Building sessions.\n",
        "Interview Questions.\n",
        "Sessions with industry mentors.\n",
        "Discussion on Job hunting strategies.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "K1qyBsV_Z2cJ"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "Y_DeGo2paJZ5"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fSJo6j3bDAA",
        "outputId": "9622831b-3b6e-4087-9fc4-e0edd0f0aab8"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "346"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g01G1RtlgbyM",
        "outputId": "5cc6cb75-2382-4a47-9546-f920218b3819"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   0,  71],\n",
              "       [  0,   0,   0, ...,   0,  71,   1],\n",
              "       [  0,   0,   0, ...,   0,   0,  16],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   0, 344,  14],\n",
              "       [  0,   0,   0, ..., 344,  14,  58],\n",
              "       [  0,   0,   0, ...,  14,  58, 345]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence = []\n",
        "for i in faqs.split('\\n'):\n",
        "  tokenized_sentence=Token.texts_to_sequences([i])[0]\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequence.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "U-IKCdaLbFMb"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now applt the padding\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "max_length=max([len(x) for x in input_sequence])\n",
        "input_sequence = np.array(pad_sequences(input_sequence,maxlen=max_length,padding='pre'))"
      ],
      "metadata": {
        "id": "Q2QzZpBUblrC"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=input_sequence[:,:-1]\n",
        "y=input_sequence[:,-1]\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes=347)"
      ],
      "metadata": {
        "id": "rpCB68sogj3U"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense"
      ],
      "metadata": {
        "id": "lyPiq_RliaRY"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model = Sequential()\n",
        "Model.add(Embedding(347,100,input_length=62))\n",
        "Model.add(LSTM(150))\n",
        "Model.add(Dense(347,activation='softmax'))"
      ],
      "metadata": {
        "id": "JJxNVwBejalM"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "atTmKqhaj-dB"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model.fit(x,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-pLWtvek0Bl",
        "outputId": "6961ec57-db31-4037-f25c-9bba84033141"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - accuracy: 0.0245 - loss: 5.7166\n",
            "Epoch 2/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 175ms/step - accuracy: 0.0608 - loss: 5.2101\n",
            "Epoch 3/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 115ms/step - accuracy: 0.0628 - loss: 5.1876\n",
            "Epoch 4/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 169ms/step - accuracy: 0.0644 - loss: 5.0970\n",
            "Epoch 5/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - accuracy: 0.0726 - loss: 4.9900\n",
            "Epoch 6/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 178ms/step - accuracy: 0.0970 - loss: 4.8319\n",
            "Epoch 7/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 117ms/step - accuracy: 0.0951 - loss: 4.7845\n",
            "Epoch 8/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 151ms/step - accuracy: 0.1192 - loss: 4.5981\n",
            "Epoch 9/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 149ms/step - accuracy: 0.1392 - loss: 4.4065\n",
            "Epoch 10/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - accuracy: 0.1911 - loss: 4.1952\n",
            "Epoch 11/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - accuracy: 0.2140 - loss: 3.8898\n",
            "Epoch 12/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.2558 - loss: 3.6556\n",
            "Epoch 13/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 0.2813 - loss: 3.4246\n",
            "Epoch 14/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 177ms/step - accuracy: 0.2841 - loss: 3.2860\n",
            "Epoch 15/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - accuracy: 0.3545 - loss: 3.0469\n",
            "Epoch 16/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.3743 - loss: 2.8334\n",
            "Epoch 17/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.4082 - loss: 2.6460\n",
            "Epoch 18/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - accuracy: 0.4631 - loss: 2.4653\n",
            "Epoch 19/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 139ms/step - accuracy: 0.4872 - loss: 2.3713\n",
            "Epoch 20/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - accuracy: 0.5039 - loss: 2.2085\n",
            "Epoch 21/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - accuracy: 0.5505 - loss: 2.0476\n",
            "Epoch 22/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - accuracy: 0.5885 - loss: 1.9733\n",
            "Epoch 23/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - accuracy: 0.6309 - loss: 1.8122\n",
            "Epoch 24/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - accuracy: 0.6812 - loss: 1.6542\n",
            "Epoch 25/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - accuracy: 0.7073 - loss: 1.5995\n",
            "Epoch 26/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - accuracy: 0.7432 - loss: 1.4210\n",
            "Epoch 27/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - accuracy: 0.7719 - loss: 1.3253\n",
            "Epoch 28/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.7827 - loss: 1.2515\n",
            "Epoch 29/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 127ms/step - accuracy: 0.8220 - loss: 1.1309\n",
            "Epoch 30/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - accuracy: 0.8245 - loss: 1.1346\n",
            "Epoch 31/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 173ms/step - accuracy: 0.8303 - loss: 1.0164\n",
            "Epoch 32/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - accuracy: 0.8507 - loss: 0.9755\n",
            "Epoch 33/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 168ms/step - accuracy: 0.8482 - loss: 0.9041\n",
            "Epoch 34/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - accuracy: 0.8600 - loss: 0.8606\n",
            "Epoch 35/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - accuracy: 0.8700 - loss: 0.7930\n",
            "Epoch 36/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 139ms/step - accuracy: 0.8794 - loss: 0.7554\n",
            "Epoch 37/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.8918 - loss: 0.6905\n",
            "Epoch 38/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - accuracy: 0.8938 - loss: 0.6530\n",
            "Epoch 39/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - accuracy: 0.9113 - loss: 0.6024\n",
            "Epoch 40/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - accuracy: 0.9066 - loss: 0.5701\n",
            "Epoch 41/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 139ms/step - accuracy: 0.9104 - loss: 0.5659\n",
            "Epoch 42/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - accuracy: 0.9221 - loss: 0.5146\n",
            "Epoch 43/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - accuracy: 0.9287 - loss: 0.4803\n",
            "Epoch 44/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - accuracy: 0.9293 - loss: 0.4653\n",
            "Epoch 45/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9345 - loss: 0.4381\n",
            "Epoch 46/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 173ms/step - accuracy: 0.9254 - loss: 0.4406\n",
            "Epoch 47/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - accuracy: 0.9411 - loss: 0.3986\n",
            "Epoch 48/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 171ms/step - accuracy: 0.9278 - loss: 0.3986\n",
            "Epoch 49/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 115ms/step - accuracy: 0.9327 - loss: 0.3761\n",
            "Epoch 50/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - accuracy: 0.9417 - loss: 0.3677\n",
            "Epoch 51/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - accuracy: 0.9431 - loss: 0.3319\n",
            "Epoch 52/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - accuracy: 0.9350 - loss: 0.3372\n",
            "Epoch 53/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.9416 - loss: 0.3136\n",
            "Epoch 54/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - accuracy: 0.9384 - loss: 0.3131\n",
            "Epoch 55/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.9462 - loss: 0.2907\n",
            "Epoch 56/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 114ms/step - accuracy: 0.9407 - loss: 0.2841\n",
            "Epoch 57/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 171ms/step - accuracy: 0.9351 - loss: 0.2876\n",
            "Epoch 58/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 115ms/step - accuracy: 0.9410 - loss: 0.2776\n",
            "Epoch 59/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 0.9411 - loss: 0.2616\n",
            "Epoch 60/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - accuracy: 0.9419 - loss: 0.2529\n",
            "Epoch 61/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 171ms/step - accuracy: 0.9523 - loss: 0.2429\n",
            "Epoch 62/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 116ms/step - accuracy: 0.9373 - loss: 0.2531\n",
            "Epoch 63/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 169ms/step - accuracy: 0.9479 - loss: 0.2297\n",
            "Epoch 64/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - accuracy: 0.9457 - loss: 0.2426\n",
            "Epoch 65/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - accuracy: 0.9450 - loss: 0.2331\n",
            "Epoch 66/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.9507 - loss: 0.2155\n",
            "Epoch 67/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - accuracy: 0.9428 - loss: 0.2192\n",
            "Epoch 68/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 0.9347 - loss: 0.2172\n",
            "Epoch 69/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - accuracy: 0.9407 - loss: 0.2185\n",
            "Epoch 70/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - accuracy: 0.9427 - loss: 0.2105\n",
            "Epoch 71/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - accuracy: 0.9430 - loss: 0.2039\n",
            "Epoch 72/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - accuracy: 0.9505 - loss: 0.1843\n",
            "Epoch 73/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - accuracy: 0.9514 - loss: 0.1874\n",
            "Epoch 74/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 142ms/step - accuracy: 0.9513 - loss: 0.1806\n",
            "Epoch 75/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - accuracy: 0.9421 - loss: 0.1991\n",
            "Epoch 76/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - accuracy: 0.9391 - loss: 0.1860\n",
            "Epoch 77/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 171ms/step - accuracy: 0.9666 - loss: 0.1591\n",
            "Epoch 78/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 114ms/step - accuracy: 0.9473 - loss: 0.1813\n",
            "Epoch 79/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 174ms/step - accuracy: 0.9453 - loss: 0.1703\n",
            "Epoch 80/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 118ms/step - accuracy: 0.9533 - loss: 0.1550\n",
            "Epoch 81/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 150ms/step - accuracy: 0.9543 - loss: 0.1500\n",
            "Epoch 82/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - accuracy: 0.9455 - loss: 0.1782\n",
            "Epoch 83/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9536 - loss: 0.1621\n",
            "Epoch 84/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 178ms/step - accuracy: 0.9528 - loss: 0.1448\n",
            "Epoch 85/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 117ms/step - accuracy: 0.9453 - loss: 0.1511\n",
            "Epoch 86/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 167ms/step - accuracy: 0.9463 - loss: 0.1477\n",
            "Epoch 87/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - accuracy: 0.9348 - loss: 0.1754\n",
            "Epoch 88/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 169ms/step - accuracy: 0.9578 - loss: 0.1427\n",
            "Epoch 89/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 123ms/step - accuracy: 0.9515 - loss: 0.1429\n",
            "Epoch 90/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 160ms/step - accuracy: 0.9554 - loss: 0.1485\n",
            "Epoch 91/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 148ms/step - accuracy: 0.9374 - loss: 0.1570\n",
            "Epoch 92/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - accuracy: 0.9464 - loss: 0.1499\n",
            "Epoch 93/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - accuracy: 0.9461 - loss: 0.1376\n",
            "Epoch 94/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 173ms/step - accuracy: 0.9549 - loss: 0.1432\n",
            "Epoch 95/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - accuracy: 0.9422 - loss: 0.1478\n",
            "Epoch 96/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 115ms/step - accuracy: 0.9555 - loss: 0.1329\n",
            "Epoch 97/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - accuracy: 0.9422 - loss: 0.1534\n",
            "Epoch 98/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 132ms/step - accuracy: 0.9465 - loss: 0.1339\n",
            "Epoch 99/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.9507 - loss: 0.1379\n",
            "Epoch 100/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - accuracy: 0.9375 - loss: 0.1491\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa7c858b040>"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message = \"the course fee\"\n",
        "for i in range(10):\n",
        "  token_text = tokenizer.texts_to_sequences([message])[0]\n",
        "  padded_seq = pad_sequences([token_text],maxlen=max_length,padding='pre')\n",
        "  position=np.argmax(Model.predict(padded_seq))\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index == position:\n",
        "      message = message + \" \" + word\n",
        "      print(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiEkL8LHqNYM",
        "outputId": "e501ee88-f0f1-400f-c453-52d3373f2562"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "the course fee for\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "the course fee for the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "the course fee for the dsmp\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "the course fee for the dsmp 2\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "the course fee for the dsmp 2 0\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "the course fee for the dsmp 2 0 course\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "the course fee for the dsmp 2 0 course is\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "the course fee for the dsmp 2 0 course is rs\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "the course fee for the dsmp 2 0 course is rs 10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "the course fee for the dsmp 2 0 course is rs 10 600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dM0yx1p9s510"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}